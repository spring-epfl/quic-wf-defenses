{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports and functions, does nothing\n",
    "\n",
    "from IPython.display import Image\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from json import JSONEncoder\n",
    "import json\n",
    "\n",
    "class NumpyArrayEncoder(JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return JSONEncoder.default(self, obj)\n",
    "\n",
    "def serialize(uri, o, version=''):\n",
    "    try:\n",
    "        os.remove(\".cache/\"+uri)\n",
    "    except:\n",
    "        pass\n",
    "    with open(\".cache/\"+uri, \"w\") as f:\n",
    "        if version != '':\n",
    "            f.write('#version: '+version+'\\n')\n",
    "        json.dump(o, f, cls=NumpyArrayEncoder)\n",
    "\n",
    "def deserialize(uri, version=''):\n",
    "    if os.path.isfile(\".cache/\"+uri):\n",
    "        with open(\".cache/\"+uri, \"r\") as f:\n",
    "            data = []\n",
    "            for line in f:\n",
    "                if not line.startswith('#version:'):\n",
    "                    data.append(line)\n",
    "            return json.loads(''.join(data))\n",
    "    return None\n",
    "\n",
    "def load_or_compute(uri, compute_function, rebuild=False):\n",
    "    data = None\n",
    "    if not rebuild:\n",
    "        data = deserialize(uri)\n",
    "    if data is None:\n",
    "        data = compute_function()\n",
    "        serialize(uri, data)\n",
    "        return data\n",
    "    return data\n",
    "\n",
    "def img(path, width=400):\n",
    "    rnd = random.randint(0,2e9)\n",
    "    return f\"\"\"<img src=\"{path}?nocache={rnd}\" style=\"width:{width}px; \"></img>\"\"\"\n",
    "\n",
    "def plot_fi(features_of_interest, title):\n",
    "    features_of_interest.sort(key=lambda row: row[1], reverse=True) # truncate top ten\n",
    "    features_of_interest = features_of_interest[:10]\n",
    "    features_of_interest.sort(key=lambda row: row[1], reverse=False) # plotting needs ascending order\n",
    "\n",
    "    xs = [x[0] for x in features_of_interest]\n",
    "    ys = [y[1] for y in features_of_interest]\n",
    "    yerr = [[min(y[1], y[2]) for y in features_of_interest], [y[2] for y in features_of_interest]]\n",
    "\n",
    "    plt.barh(xs, ys, xerr=yerr)\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load .npy dataset of HAR files 40 loops\n",
    "data_all = np.load('datasets/quic-100p-150-40runs.npy', allow_pickle=True).item()\n",
    "# Use the dataset without ad-blocking\n",
    "data = data_all['nofilter']\n",
    "urls = [url for url in data]\n",
    "\n",
    "def add(a, b):\n",
    "    x = 0\n",
    "    if a is not None:\n",
    "        x += abs(a)\n",
    "    if b is not None:\n",
    "        x += abs(b)\n",
    "    return x\n",
    "\n",
    "def toOldHARFormat(data):\n",
    "    data2 = {}\n",
    "    for url in data:\n",
    "        data2[url] = {}\n",
    "        for sample in data[url]:\n",
    "            data2[url][sample] = []\n",
    "            for request in data[url][sample]:\n",
    "                domain, fullurl, t, out_h, out_b, t_resp, inc_h, inc_b = request\n",
    "                data2[url][sample].append([t, add(out_h, out_b), add(inc_h, inc_b)])\n",
    "    return data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.features import *\n",
    "from lib.rf import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split\n"
     ]
    }
   ],
   "source": [
    "# split in 1st/3rd/google\n",
    "\n",
    "def is_google_domain(d):\n",
    "    d = d.lower().strip()\n",
    "    if d.endswith('ggpht.com'):\n",
    "        return True\n",
    "    if \"google\" in d or \"youtube\" in d or \"doubleclick\" in d or \"gstatic.com\" in d:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "data_1st = {}\n",
    "data_3rd = {}\n",
    "data_google = {}\n",
    "for url in data:\n",
    "    data_1st[url] = {}\n",
    "    data_3rd[url] = {}\n",
    "    data_google[url] = {}\n",
    "    for sample in data[url]:\n",
    "        data_1st[url][sample] = []\n",
    "        data_3rd[url][sample] = []\n",
    "        data_google[url][sample] = []\n",
    "        for request in data[url][sample]:\n",
    "            domain, fullurl, t, out_h, out_b, t_resp, inc_h, inc_b = request\n",
    "\n",
    "            if url.lower() in domain.lower():\n",
    "                data_1st[url][sample].append(request)\n",
    "            else:\n",
    "                data_3rd[url][sample].append(request)\n",
    "            if is_google_domain(domain):\n",
    "                data_google[url][sample].append(request)\n",
    "    \n",
    "\n",
    "print(\"Data split\")\n",
    "\n",
    "def attack_and_plot(data, title):\n",
    "    features = get_features(data)\n",
    "    clf_res = rf_with_rfe(features, n_classes=141)\n",
    "    print(clf_res)\n",
    "    plot_fi(clf_res['features'], title=title)\n",
    "    return clf_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "a = []\n",
    "f = []\n",
    "t = []\n",
    "g = []\n",
    "\n",
    "for k, samples in data.items():\n",
    "    empty_samples = [s for s in samples if len(samples[s]) == 0]\n",
    "    if (len(samples) >= 20) and (len(empty_samples) <= 5):\n",
    "        a.append(k)\n",
    "    \n",
    "for k, samples in data_1st.items():\n",
    "    empty_samples = [s for s in samples if len(samples[s]) == 0]\n",
    "    if (len(samples) >= 20) and (len(empty_samples) <= 5):\n",
    "        f.append(k)\n",
    "    \n",
    "for k, samples in data_3rd.items():\n",
    "    empty_samples = [s for s in samples if len(samples[s]) == 0]\n",
    "    if (len(samples) >= 20) and (len(empty_samples) <= 5):\n",
    "        t.append(k)\n",
    "    \n",
    "for k, samples in data_google.items():\n",
    "    empty_samples = [s for s in samples if len(samples[s]) == 0]\n",
    "    if (len(samples) >= 20) and (len(empty_samples) <= 5):\n",
    "        g.append(k)\n",
    "    \n",
    "#Get sites common to all datasets\n",
    "common = list(set(a) & set(f) & set(t) & set(g))\n",
    "print(len(common))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dataset for common sites\n",
    "data_new = {key: data[key] for key in common}\n",
    "data_1st_new = {key: data_1st[key] for key in common}\n",
    "data_3rd_new = {key: data_3rd[key] for key in common}\n",
    "data_google_new = {key: data_google[key] for key in common}\n",
    "\n",
    "data = data_new\n",
    "data_1st = data_1st_new\n",
    "data_3rd = data_3rd_new\n",
    "data_google = data_google_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[feature_extract] Number of classes 100\n",
      "[feature_extract] Number of features 123\n",
      "[feature_extract] Number of samples 3363\n",
      "[feature_extract] Number of labels 3363\n",
      "Number of classes 100\n",
      "Number of features 123\n",
      "Number of samples 3363\n",
      "Number of labels 3363\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "Fold 6\n",
      "Fold 7\n",
      "Fold 8\n",
      "Fold 9\n",
      "[feature_extract] Number of classes 100\n",
      "[feature_extract] Number of features 123\n",
      "[feature_extract] Number of samples 3363\n",
      "[feature_extract] Number of labels 3363\n",
      "Number of classes 100\n",
      "Number of features 123\n",
      "Number of samples 3363\n",
      "Number of labels 3363\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "Fold 6\n",
      "Fold 7\n",
      "Fold 8\n",
      "Fold 9\n",
      "[feature_extract] Number of classes 100\n",
      "[feature_extract] Number of features 123\n",
      "[feature_extract] Number of samples 3363\n",
      "[feature_extract] Number of labels 3363\n",
      "Number of classes 100\n",
      "Number of features 123\n",
      "Number of samples 3363\n",
      "Number of labels 3363\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "Fold 6\n",
      "Fold 7\n",
      "Fold 8\n",
      "Fold 9\n",
      "[feature_extract] Number of classes 100\n",
      "[feature_extract] Number of features 123\n",
      "[feature_extract] Number of samples 3363\n",
      "[feature_extract] Number of labels 3363\n",
      "Number of classes 100\n",
      "Number of features 123\n",
      "Number of samples 3363\n",
      "Number of labels 3363\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "Fold 6\n",
      "Fold 7\n",
      "Fold 8\n",
      "Fold 9\n"
     ]
    }
   ],
   "source": [
    "def attack(data):\n",
    "    features = get_features(data)\n",
    "    return rf_with_rfe(features, n_classes=len(common))\n",
    "\n",
    "clf_results = {}\n",
    "clf_results['all'] = attack(toOldHARFormat(data))\n",
    "clf_results['1st'] = attack(toOldHARFormat(data_1st))\n",
    "clf_results['3rd'] = attack(toOldHARFormat(data_3rd))\n",
    "clf_results['google'] = attack(toOldHARFormat(data_google))\n",
    "np.save('datasets/attack_by_parties.npy', clf_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'all': {'score': {'accuracy': (0.9698365527488855, 0.006712842197965216), 'precision': (0.9741682539682539, 0.00561689262845105), 'recall': (0.969657142857143, 0.006905256139947033), 'f1score': (0.9694916166994341, 0.006923055278620777)}, 'features': [('bytes_outgoing', 0.11988490805192839, 0.0059498983682333955), ('bytes_total', 0.11909149117158446, 0.003885135245277039), ('bytes_incoming', 0.12118054927369488, 0.007864698273361182), ('bytes_%_in', 0.10443707419881092, 0.005421408786461499), ('bytes_%_out', 0.10309698021250575, 0.004484259652080371), ('hist_2006', 0.0927124816052653, 0.004922753619486559), ('n_outgoing', 0.08887569549709519, 0.00896767029909386), ('n_total', 0.06777687183616564, 0.03477798530783672), ('hist_1672', 0.04766280541300781, 0.039068518258798764), ('n_incoming', 0.07529382584978664, 0.026235909709618428), ('hist_2341', 0.05998731689015503, 0.039292307788619925)]}, '1st': {'score': {'accuracy': (0.9827637444279347, 0.005069456793233891), 'precision': (0.9849379509379508, 0.0043546874021253125), 'recall': (0.9825726190476191, 0.004970044763847583), 'f1score': (0.9824508008331538, 0.005205830512802217)}, 'features': [('bytes_outgoing', 0.140968474248821, 0.007436169172738385), ('bytes_%_out', 0.13314830952313322, 0.004527468023408761), ('bytes_incoming', 0.13353338688681854, 0.005641533516960444), ('bytes_total', 0.13235190707592173, 0.0051351929901393865), ('bytes_%_in', 0.12826225485615547, 0.0046799052412873805), ('n_incoming', 0.052091971498534576, 0.03471088878413105), ('n_total', 0.07706201609883703, 0.008024115184341851), ('hist_2341', 0.058847412316412974, 0.0034912366882401285), ('hist_2006', 0.03854267119090492, 0.025268447763709345), ('time_incoming_p100', 0.0054054318976824115, 0.016216295693047236), ('n_outgoing', 0.05914096128303496, 0.030577400131677437), ('intertime_outgoing_avg', 0.0068444352508108455, 0.020533305752432538), ('times_sum', 0.011968688003735448, 0.02395045398834532), ('l30_n_incoming', 0.004255038494847492, 0.012765115484542474), ('intertime_incoming_avg', 0.006677894641169959, 0.02003368392350988), ('time_p100', 0.0055646474765236684, 0.016693942429571004), ('time_incoming_p25', 0.005334499256655798, 0.01600349776996739)]}, '3rd': {'score': {'accuracy': (0.9689450222882614, 0.007676428738834737), 'precision': (0.972830808080808, 0.006906472737049025), 'recall': (0.9683226190476191, 0.008280328795081058), 'f1score': (0.9681962911271734, 0.008352865301966153)}, 'features': [('bytes_outgoing', 0.15839444755961601, 0.009155664369585604), ('bytes_incoming', 0.12945857111905384, 0.005591343665341494), ('bytes_total', 0.12658532708549192, 0.004560920736309752), ('time_outgoing_p25', 0.07058610750191441, 0.03675323491114493), ('bytes_%_out', 0.0985787266076496, 0.004495728194096797), ('bytes_%_in', 0.10083963282566337, 0.005511351760282644), ('time_incoming_p75', 0.008293446056245327, 0.024880338168735982), ('time_outgoing_p50', 0.0075920531031401905, 0.022776159309420566), ('hist_1672', 0.06811155617215514, 0.003167801892122884), ('hist_2006', 0.06506580681518247, 0.0029508660752411513), ('time_p25', 0.02380176320141734, 0.03657499092279259), ('time_incoming_p25', 0.0476936427482106, 0.039427527201437065), ('n_total', 0.010639561901629303, 0.031918685704887914), ('times_sum', 0.0355300173948145, 0.04354786498712545), ('n_incoming', 0.009626220726092934, 0.028878662178278794), ('intertime_incoming_avg', 0.024089915324237952, 0.03681484049948209), ('time_incoming_p50', 0.007787578053913671, 0.023362734161741016), ('time_p75', 0.007325625803571436, 0.02197687741071431)]}, 'google': {'score': {'accuracy': (0.9707280832095095, 0.005441258075364187), 'precision': (0.9740176046176046, 0.004858588801802224), 'recall': (0.970334523809524, 0.005775376444229622), 'f1score': (0.9698317615219318, 0.005733712869099818)}, 'features': [('bytes_outgoing', 0.16538963090381023, 0.00695072384756106), ('bytes_incoming', 0.1285489844246795, 0.003751955598651318), ('bytes_total', 0.13010309221824018, 0.005033741246336884), ('bytes_%_out', 0.10493602321929388, 0.00509088592416144), ('bytes_%_in', 0.10213775787839834, 0.004626882282733955), ('time_outgoing_p25', 0.055907250352253066, 0.03690536167544887), ('f30_n_incoming', 0.008837747193359353, 0.02651324158007806), ('times_sum', 0.06089454165035777, 0.040279449455513684), ('hist_1672', 0.05394938246143081, 0.018132293125473577), ('hist_2006', 0.046486063348252074, 0.02334249582787851), ('time_p25', 0.024887331005280938, 0.03810125435951234), ('intertime_outgoing_avg', 0.016214629531440754, 0.032437551797340876), ('time_p50', 0.01516896106266851, 0.030390053394257707), ('time_incoming_p25', 0.052546113130985984, 0.034668457320046184), ('n_total', 0.009114535603444834, 0.027343606810334504), ('intertime_incoming_avg', 0.008654650722040597, 0.025963952166121795), ('time_outgoing_p50', 0.00775922368275216, 0.023277671048256482), ('intertime_avg', 0.008464081611311156, 0.025392244833933472)]}}\n"
     ]
    }
   ],
   "source": [
    "clf_results = np.load('datasets/attack_by_parties.npy', allow_pickle=True).item()\n",
    "print(clf_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
